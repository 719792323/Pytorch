{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"data\", train=False, transform=trans, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=4),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=256)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Flatten(start_dim=1, end_dim=-1)\n  (1): Linear(in_features=784, out_features=10, bias=True)\n)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义网络\n",
    "# PyTorch不会隐式地调整输⼊的形状。因此，\n",
    "# 在线性层前定义了展平层（flatten），来调整⽹络输⼊的形状\n",
    "# 好比假如输入数据是(256,1,28,28)，nn.Flatten会将数据转换为(256,784)，\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "\n",
    "\n",
    "# 初始化网络模型参数\n",
    "def init_weights(m):\n",
    "    # 全连接层的初始化策略\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "\n",
    "net.apply(init_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "\"\"\"\n",
    "溢出问题：\n",
    "softmax函数exp计算如果其中的⼀些数值⾮常⼤，那么exp可能⼤于数据类型容许的最⼤数字，即上溢（overflow）。\n",
    "这将使分母或分⼦变为inf（⽆穷⼤），最后得到的是0、 inf、nan（不是数字）。\n",
    "在这些情况下，我们⽆法得到⼀个明确定义的交叉熵值。\n",
    "如果把数据中所有值减去其中最大值，那么很可能让exp计算结果为0，然后计算log的交叉熵时趋于-inf，造成下溢问题。\n",
    "解决方案的原理：见127p\n",
    "解决方案的函数：loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\"\"\"\n",
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# 优化函数\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.44337307516733804, 0.84965) 0.8341\n",
      "(0.4389319231033325, 0.8499) 0.8324\n",
      "(0.43565808022816976, 0.8519166666666667) 0.8336\n",
      "(0.4333226386388143, 0.8518) 0.8355\n",
      "(0.43013443806966145, 0.85365) 0.8333\n",
      "(0.4285124114990234, 0.85425) 0.8381\n",
      "(0.42558628187179565, 0.8546666666666667) 0.8369\n",
      "(0.4241584191640218, 0.8554833333333334) 0.8372\n",
      "(0.4224583350499471, 0.85545) 0.8371\n",
      "(0.4198314774195353, 0.85705) 0.8379\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    # 将y_hat进行类型转换\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    # 返回预测正确的个数\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "\n",
    "def train_epoch_ch3(net, train_iter, loss, updater):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        print(train_metrics, test_acc)\n",
    "\n",
    "# 训练\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([256, 1, 28, 28]), torch.Size([256]))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=next(iter(test_iter))\n",
    "X.shape,y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.8555)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(net(X),axis=1)==y).sum()/len(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}